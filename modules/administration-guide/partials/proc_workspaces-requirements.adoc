// {prod-id-short}-compute-resources-requirements

[id="workspaces-requirements_{context}"]
= Workspaces requirements

This section describes how to calculate the resources required for a workspace. It is the sum of the resources required for each component of this workspace.

These examples demonstrate the necessity of a proper calculation:

* A workspace with ten active plug-ins requires more resources than the same workspace with fewer plug-ins.
* A standard Java workspace requires more resources than a standard Node.js workspace because running builds, tests, and application debugging requires more resources.

.Procedure

. Identify the workspace components explicitly specified in the `components` section of the xref:end-user-guide:authoring-devfiles-version-2.adoc[].

. Identify the implicit workspace components:
+
.. {prod-short} implicitly loads the default `cheEditor`: `che-theia`, and the `chePlugin` that allows commands execution: `che-machine-exec-plugin`. To change the default editor, add a  `cheEditor` component section in the devfile.

.. The JWT Proxy component is responsible for the authentication and authorization of the external communications of the workspace components.

. Calculate the requirements for each component:
+
.. Default values:
+
The following table displays the default requirements for all workspace components, and the corresponding {prod-short} server properties. Use the {prod-short} server properties to modify the defaults cluster-wide.
+
[cols="3,2,1,1", options="header"]
.Default requirements of workspace components by type
|===
|Component types
|{prod-short} server property
|Default memory limit
|Default memory request

|`chePlugin`
|`che.workspace.sidecar.default_memory_limit_mb`
|128 MiB
|64 MiB

|`cheEditor`
|`che.workspace.sidecar.default_memory_limit_mb`
|128 MiB
|64 MiB


|`kubernetes`, `openshift`, `dockerimage`
|`che.workspace.default_memory_limit_mb`, `che.workspace.default_memory_request_mb`
|1 Gi
|200 MiB

|`JWT Proxy`
|`che.server.secure_exposer.jwtproxy.memory_limit`, `che.server.secure_exposer.jwtproxy.memory_request`
|128 MiB
|15 MiB
|===

.. Custom requirements for `chePlugins` and `cheEditors` components:
+
... Custom memory limit and request:
+
Define the `memoryLimit` and `memoryRequest` attributes of the `containers` section of the `meta.yaml` file to configure the memory limit of the `chePlugins` or `cheEditors` components. {prod-short} automatically sets the memory request to match the memory limit if it is not specified explicitly.
+
.The `chePlugin` `che-incubator/typescript/latest`
====
.`meta.yaml` spec section:
[source,yaml]
----
spec:
 containers:
   - image: docker.io/eclipse/che-remote-plugin-node:next
     name: vscode-typescript
     memoryLimit: 512Mi
     memoryRequest: 256Mi
----

This results in a container with the following memory limit and request:

|===
|Memory limit | 512 MiB
|Memory request | 256 MiB
|===
====
+
include::example$snip_{project-context}-memory-requirement-note.adoc[]
+
[NOTE]
====
.How to find the `meta.yaml` file of `chePlugin`

Community plug-ins are available in the link:https://github.com/eclipse-che/che-plugin-registry[{prod-short} plug-ins registry repository] in folder `v3/plugins/$\{organization}/$\{name}/$\{version}/`.

For non-community or customized plug-ins, the `meta.yaml` files are available on the local {platforms-name} cluster at `$\{pluginRegistryEndpoint}/v3/plugins/$\{organization}/$\{name}/$\{version}/meta.yaml`.

ifeval::["{project-context}" == "che"]
For example, on a local Minikube cluster, the URL for the `che-incubator/typescript/latest meta.yaml` is `+http://plugin-registry-che.192.168.64.78.nip.io/v3/plugins/che-incubator/typescript/latest/meta.yaml+`.
endif::[]
====

... Custom CPU limit and request:
+
{prod-short} does not set CPU limits and requests by default. However, it is possible to configure CPU limits
for the `chePlugin` and `cheEditor` types in the `meta.yaml` file or in the devfile in the same way as it done for memory limits.
+
.The `chePlugin` `che-incubator/typescript/latest`
====
.`meta.yaml` spec section:
[source,yaml]
----
spec:
 containers:
   - image: docker.io/eclipse/che-remote-plugin-node:next
     name: vscode-typescript
     cpuLimit: 2000m
     cpuRequest: 500m
----

It results in a container with the following CPU limit and request:

|===
|CPU limit | 2 cores
|CPU request | 0.5 cores
|===
====

To set CPU limits and requests globally, use the following dedicated environment variables:
|===
| `CPU Limit` | `+CHE_WORKSPACE_SIDECAR_DEFAULT__CPU__LIMIT__CORES+`
| `CPU Request` | `+CHE_WORKSPACE_SIDECAR_DEFAULT__CPU__REQUEST__CORES+`
|===

See also xref:installation-guide:advanced-configuration-options-for-the-che-server-component.adoc[].

Note that the `LimitRange` object of the {platforms-namespace} may specify defaults for CPU limits and requests set by cluster administrators. To prevent start errors due to resources overrun, limits on application or workspace levels must comply with those settings.


.. Custom requirements for `dockerimage` components
+
Define the `memoryLimit` and `memoryRequest` attributes of the devfile to configure the memory limit of a `dockerimage` container. {prod-short} automatically sets the memory request to match the memory limit if it is not specified explicitly.
+
[source,yaml]
----
  - alias: maven
    type: dockerimage
    image: eclipse/maven-jdk8:latest
    memoryLimit: 1536M
----

.. Custom requirements for `kubernetes` or `openshift` components:
+
The referenced manifest may define the memory requirements and limits.

. Add all previously calculated requirements.

.Additional resources

* xref:administration-guide:che-workspaces-architecture-with-che-server.adoc[].

