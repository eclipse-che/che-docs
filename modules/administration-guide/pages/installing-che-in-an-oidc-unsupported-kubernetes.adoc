:_content-type: PROCEDURE
:navtitle: Installing {prod-short} in an OIDC Unsupported {kubernetes}
:description: Installing {prod-short} in {kubernetes} that doesn't support OIDC yet.
:keywords: installing-che-in-an-unsupported-{kubernetes}
:page-aliases: installation-guide:installing-che-in-oidc-unsupported-kubernetes

[id="installing-{prod-id-short}-in-odic-unsupported-kubernetes"]
= Installing {prod-short} in OIDC Unsupported {kubernetes} Cluster

You can deploy {prod-short} into a {kubernetes} cluster that doesn't support OIDC.

WARNING: vCluster is a third party tool. See link:https://www.vcluster.com/docs/what-are-virtual-clusters[Introduction to vCluster]

.Prerequisites

* Helm CLI. See link:https://helm.sh/docs/intro/install/[Installing Helm].

* vCluster CLI. See link:https://www.vcluster.com/docs/getting-started/setup[Installing vCluster CLI].

* `{orch-cli}` stable release with `oidc-login` plugin. See link:https://kubernetes.io/docs/tasks/tools/#kubectl[Installing `{orch-cli}`], link:https://github.com/int128/kubelogin[Installing `kubelogin`].

* `{prod-cli}`. See xref:installing-the-chectl-management-tool.adoc[].

* Deploy `cert-manager`. See link:https://cert-manager.io/docs/installation[Installing cert-manager].

* Ingress Controller configured with necessary DNS Mapping. See link:https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[Ingress Controllers]

.Procedure
. Deploy https://www.keycloak.org/[Keycloak]:
+
[subs="+attributes"]
----
$ export KEYCLOAK_DOMAIN=<keycloak_domain>
$ export USER_EMAIL=<user_email>
$ export INGRESS_CLASS=<ingress_class>

$ {orch-cli} apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
  namespace: cert-manager
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: $USER_EMAIL
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          ingressClassName: $INGRESS_CLASS
---
apiVersion: v1
kind: Namespace
metadata:
  name: keycloak
---
apiVersion: v1
kind: Service
metadata:
  name: keycloak
  namespace: keycloak
  labels:
    app: keycloak
spec:
  ports:
    - name: http
      port: 80
      targetPort: 8080
  selector:
    app: keycloak
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: keycloak
  namespace: keycloak
  labels:
    app: keycloak
spec:
  replicas: 1
  selector:
    matchLabels:
      app: keycloak
  template:
    metadata:
      labels:
        app: keycloak
    spec:
      containers:
        - name: keycloak
          image: quay.io/keycloak/keycloak:24.0.1
          args: ["start-dev"]
          env:
            - name: KEYCLOAK_ADMIN 
              value: "admin"
            - name: KC_HTTP_RELATIVE_PATH  
              value: "/auth"
            - name: KEYCLOAK_ADMIN_PASSWORD
              value: "admin"
            - name: KC_PROXY
              value: "edge"
          ports:
            - name: http
              containerPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: keycloak
  namespace: keycloak
  annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: $INGRESS_CLASS
  tls:
    - hosts:
        - $KEYCLOAK_DOMAIN
      secretName: keycloak-tls
  rules:
    - host: $KEYCLOAK_DOMAIN
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: keycloak
                port:
                  number: 80
EOF
----
. Access Keycloak UI by reaching out to the `https://KEYCLOAK_DOMAIN/auth` URL in any browser, login in with the user credentials. Now to configure Admin User Account. Navigate to Users, click `admin` and make sure "FirstName", "LastName", and Email are filled in and Email Verified is set to `True`.  
+
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-configure-user.png[Keycloak Configure User]
+
. Create ClientID in Keycloak for `vCluster` and {orch-cli}. Access the Keycloak UI using the URL `https://$KEYCLOAK_DOMAIN/auth` and log in with the credentials `admin/admin`. Navigate to `Client` Page and Create Client with the following configurations
+
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-client-step-1.png[Keycloak Create Client Step 1]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-client-step-2.png[Keycloak Create Client Step 2]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-client-step-3.png[Keycloak Create Client Step 3]
+

. Create `vcluster-admin` group in Keycloak and assign the user to the group. Assign `cluster-admin` role to the `admin` user. Navigate to Users page and select `admin` user.
+
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-group.png[Keycloak Create Group]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-assign-group.png[Keycloak Assign Group]
+
. To Create ClientID in Keycloak for {prod-short}, access the Keycloak UI and Navigate to `Client` Page. Create Client with the following configurations. Note down the client credientials, client ID and client secret created by follwing these steps, this will be used later when deploying {prod-short} using {prod-cli}. 
+
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-private-client-step-1.png[Keycloak Create Client for Eclipse Che Step 1]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-private-client-step-2.png[Keycloak Create Client for Eclipse Che Step 2]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-private-client-step-3.png[Keycloak Create Client for Eclipse Che Step 3]
image::installing-che-in-oidc-unsupported-kubernetes/che-in-oidc-unsupported-kubernetes-create-private-client-step-4.png[Keycloak Client Credentials for Eclipse Che Step 4]
+
. Create `values.yaml` for vCluster's helm chart:
+
[subs="+attributes"]
----
# OIDC IssuerURL
$ export ISSUER_URL=https://$KEYCLOAK_DOMAIN/auth/realms/master
# Kubernetes ClientId
$ export KUBERNETES_CLIENT_ID=kubectl-public

$ cat > vcluster-values.yaml << EOF
api:
  image: registry.k8s.io/kube-apiserver:v1.27.1
  extraArgs:
    - --oidc-issuer-url=$ISSUER_URL
    - --oidc-client-id=$KUBERNETES_CLIENT_ID
    - --oidc-username-claim=email
    - --oidc-groups-claim=groups
init:
  manifestsTemplate: |-
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: oidc-cluster-admin
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: cluster-admin
    subjects:
    - kind: Group
      name: {{ .Values.ClusterAdminGroup }}
service:
  type: LoadBalancer
EOF
----
. Create vCluster using Helm Chart:
+
[subs="+attributes"]
----
$ kubectl create ns che-cluster
$ helm repo add loft-sh https://charts.loft.sh && helm repo update && helm install che-cluster loft-sh/vcluster-k8s -n che-cluster -f ./vcluster-values.yaml --set ClusterAdminGroup=vcluster-admin
----

. Verify the vCluster cluster status:
+
[subs="+attributes,+quotes"]
----
$ vCluster list
----
. Determine the LoadBalancer's external IP and note it for later.
+
[subs="+attributes,+quotes"]
----
$ {orch-cli} get svc che-cluster-lb -n che-cluster
----
. Retrieve the KubeConfig file
+
IMPORTANT: The secret might take an additional minute or two to be created after all the pods in `che-cluster` namespace ends up `READY`.
+
----
$ {orch-cli} get secret vc-che-cluster -n che-cluster --template={{.data.config}} | base64 -d > config
----

. Open the `config` file. The `config` file should look similar to this.
+
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJR1JpYVJkMnFQc0l3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBek1EWXhOakUwTWpsYUZ3MHpOREF6TURReE5qRTBNamxhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkREDACTEDb1BqOW9mWmREDACTEDo1MjdMc3YwcHltb2xZZEFhN2xEYzlQM3Y0b2wrVApLQmNmTmVsMFhtQzc1YTd1SWVpZmJrUmNLQUk4N2xZVXJNa2p2K3FsMGR0bTcrbXpjM3Y5WG9kdjdKQUFKSlgxClAzY2JQd3RXZ1dVVGgrVkRVTnk0cmJEQ1VkSTZHMVJiR1FtbHRzeURTcHp6anRVRFpId0Fvcnh0YXZHeldrblYKTW1NOEFDa090RE5VCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://localhost:8443
  name: my-vcluster
contexts:
- context:
    cluster: my-vcluster
    user: my-vcluster
  name: my-vcluster
current-context: my-vcluster
kind: Config
preferences: {}
users:
- name: my-vcluster
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJZVFRb3NqRnFUUUl3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5aUWpONUljSlRubDF4aFhKV3M0cE1UYmtRCkw3TVlKUEU3KzdJMVZZNVFUeDVNYUlKZVBQWE9aa1NzL0xnZlNVOUZENFFnNERnNjVukxSUdxCnhjdGduQXcwYWZXdTZ1eGFNK0lIYXA1S2RSWFRtbVpvYkhEMVlKMTZJV0Fzd2paeHhSMmhFNVY4Z2xudldndFkKcURUNnBOVWpqaXZPYUxqMmJGQ3JLSWZEcm56UVUxQlp5VnRVMjNsSlFLRkxCT3B2akE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    client-key-data: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFcEFJQkFBS0NBUUVBcy85RUZNb2lQbFBMN3JLZ3cyTGtVMDJxdmlzMDFLVlNvQ0VjMTR1ajR3V21ScTd6CnlhckpLVEZ4cCs4NElWbWtKcXdoaFFNL1pjZ0dXQXp2MjdSbkt4MDRkbXdNcHFNdytxMzNPU3FXc2Z3TVlFWFYKRmlzVFZCU3RkWExRVGI0bFV3Y0FNZDREYmFTSGpMWVFzUGNLaXIxQXE0K2ZCVzRjRW8rbWNkMFlGNUoKMWF3NkpOa0VQcndOZHpNUjJEU1VxN2ozbFdpSXl1VXBCcURiSFBCSUd5NHY5bHZ1cXlFUXEzZnVzOC9YUXJpWdyRDZRQlI1eHJ6ZGEyTXZiazVhbWVEUnVnNC8yCktzZnB3dXl4Tml0bndRbkJ4TnExQVFLQmdRQ3Q2aHR5R2cvYVIyQ2Q4eXYwNXArZVMvOXNvOUxjdWRLcGFLaW0KRm9OUDFnNENOaUFVUGwvR0tJOGJ4c2R5SzB0TlY2bHBNN2xmVUc0eVVKUmFvbThlemIzSFdMZjJXdGdkTUJ3cwpWSVplNDlQcjhkc2J1dTFQM2ZrelFyWlZoK291dmlvTmFJTGxneEtocStqYmhBZXZVUFMwdUFlSUt0THowV0IxCjgrT3V3UUtCZ1FEQU4vbzhkaFlTZjB2ZU9YOWdPQTEvR3Iwa1VYMHBzZitrSGZ5MlFHYU4vMjNmV1RrM1YvRTUKRzJrbVNiVjJIcXh3b3VRWDgzZ3ltbmJUTGorbUZ6SXFmcWE1ZHVDRXFiMEs4Y2U0RU1GVUQxd01vVEd6bzBmNQpvR3FUNW5CY1Ezc1V4Q2ZiRngyRk4zK0MyTFhRMnNRczVOTXIxZWNLZU9pdFovWlNXMlUzWmc9PQotLS0tLUVORCBSU0EgUFJJVkFURSBLRVktLS0tLQo=
----
+
. Replace the `server:` URL with the LB IP you noted earlier. (e.g. 10.1.2.3:443)
. Search and replace all occurrences of the word `my-vcluster`  with `che-cluster`.

. Replace the users part in the YAML similar the following replacing `oidc-issuer-url` and `oidc-client-id` as per your auth configurations. 
+
----
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1beta1
      command: kubectl
      args:
      - oidc-login
      - get-token
      - --oidc-issuer-url=<issuer_url>
      - --oidc-client-id=kubernetes-public
      - --oidc-extra-scope="email offline_access profile openid"
----
+
. The final KubeConfig would look similar to this
+
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJek1EUXlNREUyTURJME1Wb1hEVE16TURReE56RTJNREkwTVZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTGNCClJXcXp2NVpyRzMzeFZlbmR4b3NKeUtGc3k5SC94THBaYUpJM0lOZjQrMkY3bTZ2TWVTQm1BdmFuRFc1Wndzci8KQXZzaXhnWS9lSVFoV1NYTDcxdW9jcHllUldWQzdNc25CcjNuMVozRytpdnFhWXlhKzVGd0NrMmYxU1JNdWdlRwo4NDVUb1VmL1dqZy9MdGJCZ2lhck0rLzJCSFVYL0NoL2N3Qy9RdTltRTdnalk5a2RKM2YyUnBlT1ovdzF6dDZ3CkhVbUU2a01oQ00xSXBEZTMrNDNMc295TlA4WlcvM09sNVIxRlFFNG96V3BZckxJeGlycTd1MHZDME5aSFVkQzUKRXBkWUNDZVNVbStWM0MxdWRMV1R2eFl2RVZNNlRpL21jbHhvQ1l6cjd5WHU2dzZuUlZWMlJXMGxQejZCZng5RApHK2V5RFpaWGhHcjhZK1dmUWtNQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZBU05mTlpBOENUK1k4YXV1MXRSeUlBMVZSc2dNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBSjZQb1psN3BLN3hUK0VnSTM5aQpjNURrVjViaFFpSGpKdG5hT3lmcm5pV3pNVHBVQ1I1S3lzU0t3MmdOMUk4dFZKMStUYWNYdktOeUIyL2hjQXlPClNuNjZ2NTdoSGlQd0dsTzZqbkRpcE5lM1BndTVkUnFxT2V3Zldzd25TeTFoZWpWc2NsZ1BBQmhyWldQSmlYYW8KUDRKa0cwSEpRNXdJVmlMcW5Xd2JkY2dtaGd5aHZobFJKUk9CMU5rZkNzUTNWZnJXYU9nMncvck45aGJXOHhmcApJNnp5em5vWkpjcVZ2RFVMWG5SSTBQd1hMK2tNMnVmalhSM3BJM3BPeTJzdlltZVBUOGlaK0JqYjJ1ZkNnUnJGCmhSbk5wbHFPRGJXa01tTlBEOWZVYlIxd1hNZXJQaHIrVEQveHVmZ2VhZUxRdlhuQ2s2S1NMZmNIb0dlWVVCR1oKWVZVPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    server: https://10.1.2.3:443
  name: che-cluster
contexts:
- context:
    cluster: che-cluster
    user: che-cluster
  name: che-cluster
current-context: che-cluster
kind: Config
preferences: {}
users:
- name: che-cluster
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1beta1
      command: kubectl
      args:
      - oidc-login
      - get-token
      - --oidc-issuer-url=https://auth.sample_keycloak.com/auth/realms/master
      - --oidc-client-id=kubectl-public
      - --oidc-extra-scope="email offline_access profile openid"
----
+
. Make the newly created `kubeconfig` the current one by backing up the existing `kubeconfig` file in the user's .kube or $KUBECONFIG folder and replacing it with the new `config` file.

. Verify the vCluster cluster status:

+
[subs="+attributes,+quotes"]
----
$ kubectl get ns
----

. If everything is configured correctly, you will be redirected to authenticate with your auth server in the browser. Once authenticated you will be able to view all the namspaces. 

+
IMPORTANT: Make sure the user has `vcluster-admin` group assigned.
+

. Install Ingress Controller in the virtual `che-cluster` by pasting the following script.

[subs="+attributes"]
----
$ helm install  cert-manager jetstack/cert-manager  --namespace cert-manager  --create-namespace  --version v1.14.4  --set installCRDs=true && helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update && helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
    --version 4.7.1 \
    --namespace ingress-basic \
    --create-namespace \
    --set controller.replicaCount=1 \
----

. 

. Prepare the `CheCluster` patch.
+
[subs="+attributes"]
----
$ export CHE_CLIENT_ID=che-private

# Use the client secret created in the previous steps.
$ export CHE_CLIENT_SECRET=<client_secret>

$ export ECLIPSE_CHE_DOMAIN=<Che Deployment URL>  

$ cat > che-patch.yaml << EOF
kind: CheCluster
apiVersion: org.eclipse.che/v2
spec:
  networking:
    ingressClassName: nginx
    auth:
      oAuthClientName: $CHE_CLIENT_ID
      oAuthSecret: $CHE_CLIENT_SECRET
      identityProviderURL: $ISSUER_URL
  components:
    cheServer:
      extraProperties:
        CHE_OIDC_USERNAME__CLAIM: email
EOF
----

. Create the {prod-short} instance with `{prod-cli}`:
+
[subs="+attributes"]
----
$ {prod-cli} server:deploy --platform k8s --domain $ECLIPSE_CHE_DOMAIN --che-operator-cr-patch-yaml che-patch.yaml
----

. Verification steps

. Verify the {prod-short} instance status:
+
[subs="+attributes,+quotes"]
----
$ {prod-cli} server:status
----

. Navigate to the {prod-short} cluster instance:
+
[subs="+attributes,+quotes"]
----
$ {prod-cli} dashboard:open
----
. Log in to the {prod-short} instance with the user credentials.
